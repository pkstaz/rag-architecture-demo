{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c004acc-13cd-4917-8480-592c7c2d623b",
   "metadata": {},
   "source": [
    "## Test vLLM Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcae69bf-815a-4af7-a9d4-019adfbf7883",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain langchain-community langchain-core openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2437fef5-d852-4734-9fbd-a2e345f2c414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import VLLMOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a24909",
   "metadata": {},
   "source": [
    "### Change the Model\n",
    "\n",
    "Change the model_name variable to the model you want to test:\n",
    "\n",
    "* model_name: meta-llama/Meta-Llama-3-8B\n",
    "* model_name: mistralai/Mistral-7B-Instruct-v0.2\n",
    "* model_name: ibm-granite/granite-8b-code-instruct\n",
    "* model_name: meta-llama/Llama-2-13b-chat-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0de65d02-84a6-4cff-882e-551cdd42b486",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LLM Inference Server URL\n",
    "inference_server_url = \"http://llm1.multi-gpu-poc.svc.cluster.local:8000\"\n",
    "\n",
    "# LLM definition\n",
    "llm = VLLMOpenAI(           # we are using the vLLM OpenAI-compatible API client. But the Model is running on OpenShift, not OpenAI.\n",
    "    openai_api_key=\"EMPTY\",   # and that is why we don't need an OpenAI key for this.\n",
    "    openai_api_base= f\"{inference_server_url}/v1\",\n",
    "    model_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    top_p=0.92,\n",
    "    temperature=0.01,\n",
    "    max_tokens=512,\n",
    "    presence_penalty=1.03,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fd1c2c1-3adf-4071-a621-92395d256ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template=\"\"\"<s>[INST]<<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always be as helpful as possible, while being safe.\n",
    "You will be asked a question, to which you must give an answer.\n",
    "Your answer should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.\n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct.\n",
    "If you don't know the answer to a question, answer \"I don't know\".\n",
    "<</SYS>>\n",
    "\n",
    "### QUESTION:\n",
    "{input}\n",
    "\n",
    "### ANSWER:\n",
    "[/INST]\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(input_variables=[\"input\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45ad16ac-23da-48bd-9796-f8e4cacae981",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "conversation = LLMChain(llm=llm,\n",
    "                        prompt=PROMPT,\n",
    "                        verbose=False\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5034a476-c4fa-407b-82e5-6b600d26680c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. It involves various techniques such as machine learning, deep learning, natural language processing, and reasoning to enable systems to perform tasks that would normally require human intelligence, such as recognizing patterns, understanding speech, solving problems, and making decisions. AI systems can be designed to perform a wide range of functions, from simple automation tasks to complex problem-solving and decision-making roles. They can be found in various applications, including virtual assistants, self-driving cars, medical diagnosis systems, and financial trading algorithms."
     ]
    }
   ],
   "source": [
    "query = \"What is Artificial Intelligence?\"\n",
    "\n",
    "conversation.predict(input=query);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
